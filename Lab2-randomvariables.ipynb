{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms and the binomial distribution\n",
    "\n",
    "Histograms provide a visual representation of the empirical distribution of a data set.\n",
    "\n",
    "In this lab, we will simulate numerical experiments with random number generators to illustrate how histograms can be used to infer the true probability distribution of our random variables and the impact of finite data sets on our estimates.\n",
    "\n",
    "For simplicity, we will start with an experiment with discrete random variables (the roll of a dice). In the second part of the lab, we will move on to continuous random variables.\n",
    "\n",
    "## Part 1: Discrete Random Variables : The roll of a dice\n",
    "\n",
    "Consider a discrete random variable \\(Y\\) that can take any of the possible values in $\\{y_1,\\ldots,y_n\\}$. To estimate the probability of each value, $p_n$, we can count the frequency with which each $y_i$ occurs in our data set. This intuitive idea is justified by the law of large numbers, but we can easily illustrate it here by modeling the counting process with the binomial distribution.\n",
    "\n",
    "For clarity, we assume that the true probability of observing $y_i$ is $p_i$.\n",
    "\n",
    "The process of checking whether our random variable $y$ matches a given value $y_i$ (e.g., a particular digit in a die) can be treated as a Bernoulli trial assigned to the random variable $X_i$, where \"success\" ($x_i=0$) means that $Y=y_i$, and \"failure\" ($x_i=1$) means that $Y|\\neq y_i$. Since we are describing histograms, we refer to the event $Y=y_i$, as $Y$ being in bin $i$.\n",
    "\n",
    "In a set of $N$ trials (e.g., $N$ dice rolls), the number of times we observe $Y=y_i$ is also a random variable\n",
    "\n",
    "$$K_i=\\sum_{n=1}^N X_{i,n}.$$\n",
    "\n",
    "As we discussed in class, $K_i$ follows a binomial distribution:\n",
    "$$ P(K_i=k) =B(k,p,N)= \\binom{N}{k} p_i^k (1-p_i)^{N-k} $$\n",
    "\n",
    "**Exercises (analytical)**\n",
    "1. Calculate the expected number of observations in bin \\(x_i\\) as a function of $p_i$ and $N$.\n",
    "2. Determine the expected standard deviation (or error) from this theoretical mean for Bin $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain E[k] and Var[k] as a function of N and p\n",
    "mu=..\n",
    "\n",
    "sigma2=..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting repetitions\n",
    "\n",
    "Our numerical experiment will mimic a dice rolling experiment. To do this, we will randomly generate dice numbers with a uniform distribution, count how many times we get each of the 6 digits, and try to estimate their respective probabilities from analysis of the data.\n",
    "\n",
    "Now let's count how many times I observe a particular outcome in a series of $N$ trials.\n",
    "\n",
    "**Exercise (numerical)**\n",
    "\n",
    "3. We simulate rolling a die by uniformly generating a random number between 1 and 6, i.e., the probability of getting every possible digit is $p=1/6$. Prepare a function that returns the result of a set of $N$ trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate N random numbers, each corresponding to the number displayed after a die roll\n",
    "# the function random.randint(A,B) generates a random number between A and B with uniform probability\n",
    "\n",
    "\n",
    "def throw_dice(N): # roll N dices\n",
    "    return ...\n",
    "\n",
    "\n",
    "# we show the series of numbers obtained with each throw of the dice\n",
    "print(throw_dice(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now let's count how many times I observe a given outcome in a set of $N$ trials. To do this, follow the steps below:\n",
    "\n",
    "    a. Define a function to count how many times each number occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_elements(X,Nmax=6):\n",
    "    count=np.zeros(Nmax)\n",
    "    ...\n",
    "    \n",
    "    return count.astype(int) # return the number of times we find a 1, a 2, ...\n",
    "\n",
    "N=10\n",
    "\n",
    "#Generate a sequences of numbers\n",
    "\n",
    "X=throw_dice(N)\n",
    "#we show the sequence\n",
    "print(X)\n",
    "\n",
    "# Print the number of times we get each number\n",
    "print([str(i+1)+\":\"+str(c) for i,c in enumerate(count_elements(X))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Plot the results on a bar graph and compare them to the theoretical mean and standard deviation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=...\n",
    "N=10\n",
    "\n",
    "mean=[... for i in range(6)]  # theoretical mean for each number\n",
    "error=[... for i in range(6)] # theoretical standard deviation\n",
    "\n",
    "# we plot the counts of each number\n",
    "plt.bar(np.arange(1,7),count_elements(throw_dice(N)), capsize=5,label='experiment') \n",
    "\n",
    "#we compare with the theoretical expectation\n",
    "plt.errorbar(np.arange(1,7),mean,yerr=error,fmt='o', capsize=5,color='black',label='theoretical')\n",
    "plt.axhline(y=mean[0],ls='--',color='gray')\n",
    "\n",
    "plt.ylabel(r'$k$ repetitions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. How does this change if you increase the number of die rolls per experiment?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=1/6.\n",
    "\n",
    "for N in [10,50, 100, 1000, 10000]:\n",
    "    # redo the plot above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat the experiment several times and you will get different results. Most likely, you will get several counts that do not agree the expected value and the expected variation. Does this mean that there is a problem with the random number generator? The general answer is: it depends.\n",
    "\n",
    "If we know the theoretical distribution, the binomial distribution, we can calculate the probability that it will not match the error\n",
    "\n",
    "$$(\\mu-\\sigma > k > \\mu+\\sigma)=1-P(\\mu-\\sigma < k < \\mu+\\sigma)=1-\\sum_{k=[\\mu-\\sigma k]}^{[\\mu+\\sigma k]} B(k,N,p)$$\n",
    "\n",
    "d. For the above values of $N$, estimate the probability that the number of hits within the error is inconsistent with the theoretical values. How many of our counts do we expect to be inconsistent with the expected values? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom # we can compute the Binomial distribution \n",
    "                              #using the code binom.pmf(k, N, p)\n",
    "\n",
    "\n",
    "for N in [10, 100, 1000,10000]:\n",
    "    \n",
    "    sum_prob=0\n",
    "    \n",
    "    p=1./6\n",
    "    mean=...\n",
    "    error=...\n",
    "    \n",
    "    min_k=...\n",
    "    max_k=...\n",
    "    print(min_k,max_k)\n",
    "    \n",
    "    for k in range(min_k,max_k+1):\n",
    "        sum_prob+=binom.pmf(k, N, p)\n",
    "        \n",
    "    prob_out=1-sum_prob    \n",
    "    print(N,': prob=',prob_out, 'out of six:',prob_out*6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized histogram \n",
    "\n",
    "Instead of wondering about how often the die gives a certain number as a result, let us use it to estimate the frequency with which we get each of the numbers, which can be used as an approximation for the real probability $p_n$. The frequency is nothing more than the number of success numbers in my bin divided by the total number of trials. In other words, we now want to describe the statistics of normalized random variable:\n",
    "\n",
    "$Z_i=\\frac{1}{N}\\sum_{n=0}^N X_{i,n}=\\frac{K_i}{N}$\n",
    "\n",
    "where $X_i$ is the random variable corresponding to the Bernoilli trial of being in bin $i$.\n",
    "\n",
    "5. Which is the theoretical mean and the expected standard deviaton of this new normalized variable?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=..\n",
    "\n",
    "sigma2=..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Compute the the empirical frequency of appearance of each of the 6 numbers and compare them with the expected value and expected standard deviation. How accurate is this estimation as $N$ grows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=1/6.\n",
    "\n",
    "\n",
    "for N in [10, 100, 1000, 10000,100000]:\n",
    "    \n",
    "    mean=[... for i in range(6)] # mean of Z\n",
    "    error=[... for i in range(6)] # stardard deviation of Z\n",
    "    \n",
    "    frequency= # count the number of repetions and normalize it by the number of trials\n",
    "    \n",
    "    plt.bar(np.arange(1,7),frequency, capsize=5,label='experiment')\n",
    "    plt.errorbar(np.arange(1,7),mean,yerr=error,fmt='o', capsize=5,color='black',label='theoretical')\n",
    "    \n",
    "    plt.title(r'$N$='+str(N))\n",
    "    plt.axhline(y=1./6.,ls='--',color='gray')\n",
    "    plt.ylabel(r'freq$(y_n)$')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central limit theorem\n",
    "\n",
    "The law of large numbers states that $\\mu_Z \\to p$ as $N\\to\\infty$, and that $\\sigma^2_Z=\\frac{\\sigma_K^2}{N}$. This ensures that as the number of repetitions $N$ increases, our estimate of the probability of each event becomes finer and finer, but also that the expected fluctuations become smaller and smaller!\n",
    "\n",
    "The central limit theorem goes even further: it states that $Z$ becomes Gaussian distributed $\\mathcal{N}(\\mu,\\sigma^2)$ as the number of repetitions $N$ increases.\n",
    "\n",
    "7. We have argued that $K_i=N Z_i$ (and hence $Z$) is distributed as a binomial distribution. We can verify that this is indeed the case by repeating our experiment (rolling $N$ dices) $T=1000$ times. And examine the histogram of the results with the binomial and normal distributions. Follow the steps below to do this:\n",
    "\n",
    " a. Now consider repeating the same experiment T times and record the number of repetitions you get for each of the numbers. Since all the numbers have the same probability, we can add up all the results in the same vector of values of k_i.\n",
    "\n",
    " b. Calculate a histogram of the ks obtained to estimate the frequency with which we obtain each value.\n",
    " Plot k/N against this frequency.\n",
    "\n",
    " c. Compare the shape of the histograms as you change $N$\n",
    " \n",
    " d. For each value of $N$ compare the empirical frequency with the binomial and the normal distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x,mu,sigma2):\n",
    "    return 1./np.sqrt(2*np.pi*sigma2)*np.exp(-(x-mu)**2/(2*sigma2))\n",
    "\n",
    "def count_elements_integer(X):\n",
    "    Nmin=np.min(X)\n",
    "    Nmax=np.max(X)\n",
    "    \n",
    "    count=np.zeros(Nmax-Nmin+1)\n",
    "    for x in X:\n",
    "        count[x-Nmin]+=1\n",
    "    return np.arange(Nmin,Nmax+1),count.astype(int)\n",
    "\n",
    "T=1000\n",
    "\n",
    "for N in [5,10,50,100,1000]:\n",
    "\n",
    "    Results=np.zeros((T,6))\n",
    "    for t in range(T):\n",
    "        Results[t]=...\n",
    "\n",
    "\n",
    "    pk=Results.reshape(6*T).astype(int) # Since all numbers have the same probability, we can add up all the statistics of all them for the analysis\n",
    "    \n",
    "    \n",
    "    myrange,myhist=count_elements_integer(pk)\n",
    "    \n",
    "    plt.bar(myrange,myhist/(6*T),label=r'$N$='+str(N),alpha=0.5)\n",
    "    \n",
    "    \n",
    "    # binomial probability\n",
    "    bi_prob=...\n",
    "    plt.plot(myrange,bi_prob,'o-',color='green',label='Binomial')\n",
    "    \n",
    "    x=np.linspace(myrange[0],myrange[-1],1000)\n",
    "    mu=...\n",
    "    sigma2=...\n",
    "    plt.plot(x,gauss(x,mu,sigma2),color='orange',label='Gaussian')\n",
    "    \n",
    "    \n",
    "    plt.axvline(x=mu,ls='--',color='black')\n",
    "    plt.axvline(x=mu-np.sqrt(sigma2),ls='--',lw=3,color='gray')\n",
    "    plt.axvline(x=mu+np.sqrt(sigma2),ls='--',lw=3,color='gray')\n",
    "    plt.ylabel(r'freq$(y_n)$')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area under the Gaussian\n",
    "\n",
    "We want to estimate the probability of getting values at certain distance of the expected value.\n",
    "For this it is convenient to use the **error function**:\n",
    " \n",
    "$$erf(z)=\\frac{2}{\\sqrt{\\pi}}\\int_0^z e^{-x^2}$$\n",
    "\n",
    "Using this function, the cumulative distribution function of the $\\mathcal{N}(\\mu,\\sigma)(x)$ is\n",
    "$$F(x | \\mu, \\sigma^2) = \\frac{1}{2} \\left[ 1 + \\text{erf}\\left(\\frac{x - \\mu}{\\sigma\\sqrt{2}}\\right) \\right]$$\n",
    "\n",
    "And the area between two values $a$ and $b$\n",
    "$$\\text{Area between } a \\text{ and } b = F(b | \\mu, \\sigma^2) - F(a | \\mu, \\sigma^2)$$\n",
    "\n",
    "\n",
    "(i) Proof these two expressions\n",
    "\n",
    "(ii) Estimate the probability of  $|k-\\mu|>\\sigma$, $|k-\\mu|>2\\sigma$, $|k-\\mu|>3\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erf\n",
    "\n",
    "def gaussian_area(a, b):\n",
    "    return 0.5 * (erf(b/np.sqrt(2)) - erf(a/np.sqrt(2)))\n",
    "\n",
    "\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Continous random variables\n",
    "\n",
    "Normally, our random variables have continuous support. In such cases, the situation is very similar to the previous one, but now we discretize the support to form bins. Once the bins are defined, everything said before about the binomial distribution applies. As before, we can consider the non-normalized version, where we only count the number of hits in that bin, or the normalized case, where we need to normalize not only by the number of entries, but also by the size of the bin, if we want to obtain a function whose integral is 1.\n",
    "\n",
    "Now we generate numbers following an exponential distribution\n",
    "\n",
    "$$\n",
    "f(x,\\lambda) = \n",
    "\\begin{cases} \n",
    "\\lambda e^{-\\lambda x} & \\text{for } x \\geq 0 \\\\\n",
    "0 & \\text{for } x < 0 \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "1. Obtain the expected value of $X$ and the Variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lamb = 1.0  \n",
    "N = 1000  # Number of random numbers to generate\n",
    "\n",
    "va = np.random.exponential(1/lamb, N)\n",
    "\n",
    "def f(x,lamb):\n",
    "    return lamb*np.exp(-lamb*x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a function to obtain a normalized histogram of an array of numbers\n",
    "\n",
    "3. Which are the expected values for each interval?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do an histogram\n",
    "def count_elements(seq, NBins):\n",
    "    BInf=np.min(seq)\n",
    "    BSup=np.max(seq)\n",
    "    \n",
    "    δ = (BSup-BInf)/NBins\n",
    "    ...\n",
    "    \n",
    "    return hist,norm,bins,δ #bins gives an array with the mid point in the interval\n",
    "\n",
    "\n",
    "Nb=20\n",
    "\n",
    "h1,norm,bins,δ  = count_elements(va,Nb)\n",
    "#print(h1) # unnormalized\n",
    "#print(h1/norm) #normalized\n",
    "\n",
    "\n",
    "x=bins\n",
    "# plot the normalized histogram\n",
    "plt.bar(bins,h1/norm,width=δ ,alpha=0.5,label='empirical')\n",
    "\n",
    "#theoretical distribution\n",
    "plt.errorbar(...,color='black',label='theoretical')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Repeat the experiment $T=1000$ times and plot the distribution of the average of $X$, and compare with the Gaussian distribution expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=10000\n",
    "N=1000\n",
    "Results=np.zeros(T)\n",
    "for t in range(T):\n",
    "    Results[t]=np.mean(np.random.exponential(1/lamb, N))    \n",
    "\n",
    "Nb=20\n",
    "h1,norm,bins,δ  = ...\n",
    "x=bins\n",
    "\n",
    "# Gaussian dist\n",
    "mu=...\n",
    "sigma2=...\n",
    "plt.plot(x,gauss(x,mu,sigma2),color='orange',label='Gaussian')\n",
    "\n",
    "plt.axvline(x=mu,ls='--',color='black')\n",
    "plt.bar(bins,h1/norm,width=δ ,alpha=0.5,label='empirical')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
